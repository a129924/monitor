{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello_world_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGt_fqSmOHgV"
      },
      "source": [
        "import math\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from math import gamma\n",
        "import os\n",
        "import random\n",
        "from tabnanny import verbose\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader,ConcatDataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets"
      ],
      "metadata": {
        "id": "VNVByPkACnMa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5uTGkQMIaKY"
      },
      "source": [
        "train_tfm = transforms.Compose([\n",
        "    # transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "    ])\n",
        "\n",
        "test_tfm = transforms.Compose([\n",
        "    # transforms.ToPILImage(),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
        "    ])"
      ],
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB6dR_qwEi6x"
      },
      "source": [
        "dataset_train = datasets.MNIST(root='../data/', train=True,download=True,transform=train_tfm)\n",
        "\n",
        "dataset_test = datasets.MNIST(root='./data/',train=False,download=True,transform=test_tfm)\n",
        "                  "
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr418n01EjAG"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, feature, target=None, transform=None):\n",
        "      self.X = feature\n",
        "      self.Y = target\n",
        "      self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      # img = Image.open(self.paths[index]).convert('RGB')\n",
        "      if self.transform is not None:\n",
        "          return self.transform(self.X[idx]), self.Y[idx]\n",
        "      elif self.Y is None:\n",
        "          return [self.X[idx]]\n",
        "      return self.X[idx], self.Y[idx]\n",
        "\n",
        "\n",
        "\n",
        "    # def __init__(self, X, Y=None,tfm=train_tfm):\n",
        "    #     self.transform = tfm\n",
        "    #     self.data = X\n",
        "    #     if Y is not None:\n",
        "    #         self.label = torch.LongTensor(Y)\n",
        "    #     else:\n",
        "    #         self.label = None\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     if self.label is not None:\n",
        "    #         return self.data[idx], self.label[idx]\n",
        "    #     else:\n",
        "    #         return self.data[idx]\n",
        "\n",
        "    # def __len__(self):\n",
        "    #     return len(self.data)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Structure"
      ],
      "metadata": {
        "id": "EvBmpkEUBYxJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze-iF06lSzJU"
      },
      "source": [
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        # self.resnet50 = models.resnet50(pretrained=False,num_classes=10)\n",
        "        self.resnet50 = models.resnet50()\n",
        "\n",
        "        # self.fc = nn.Sequential(\n",
        "        #     nn.Linear(16,64),\n",
        "        #     nn.BatchNorm1d(64),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.25),\n",
        "        #     nn.Linear(64,128),\n",
        "        #     nn.BatchNorm1d(128),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Dropout(0.25),\n",
        "        #     nn.Linear(128,10),\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.resnet50(x)\n",
        "        return out"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameter\n"
      ],
      "metadata": {
        "id": "pbPICDjc8clI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Fkip8oEi4E"
      },
      "source": [
        "# fix random seed\n",
        "config = {\n",
        "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
        "    'epochs': 3000,     # Number of epochs.  \n",
        "    'folds' : 10,          \n",
        "    'batch_size': 32, \n",
        "    'weight_decay': 1e-4,\n",
        "    'learning_rate': 1e-4,              \n",
        "    'early_stop': 5,    # If model has not improved for this many consecutive epochs, stop training.     \n",
        "    'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
        "}\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# criterion = nn.MSELoss(reduction='mean')\n",
        "# model = MNISTNet().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(),lr=config['learning_rate'],weight_decay=config['weight_decay'])\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=2, T_mult=2, eta_min=config['learning_rate'])\n",
        "\n",
        "\n"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHojQunc0R6R"
      },
      "source": [
        "# def reset_weights(m):\n",
        "#     if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "#         m.reset_parameters()"
      ],
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ElLBng8Ei9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cb6b3d-730e-40ea-a468-f7289c678b78"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "MvLuNQ5I7I3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "def same_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  \n",
        "    np.random.seed(seed)  \n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "same_seed(config['seed'])\n",
        "# channel = 3     # 1 3\n",
        "# img_size = 32   # 36 32\n",
        "# train_data = FooDataset(num_data=32, shape=(channel, img_size, img_size))\n",
        "dataset_train = datasets.MNIST(root='../data/', train=True,download=True,transform=train_tfm)\n",
        "# print(len(dataset_train))\n",
        "dataset_test = datasets.MNIST(root='./data/',train=False,download=True,transform=test_tfm)\n",
        "\n",
        "## validation set\n",
        "valid_ratio = 0.2\n",
        "valid_set_size = int(valid_ratio * len(dataset_train)) \n",
        "train_set_size = len(dataset_train) - valid_set_size\n",
        "dataset_train, dataset_valid = torch.utils.data.random_split(dataset_train, [train_set_size, valid_set_size])\n",
        "\n",
        "# Pytorch data loader loads pytorch dataset into batches.\n",
        "train_loader = DataLoader(dataset_train, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(dataset_valid, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(dataset_test, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "MgAIAAxC2rFo"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test functions"
      ],
      "metadata": {
        "id": "EHmISwoVBrGb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoEEw_VpUY_R"
      },
      "source": [
        "best_acc = 0.0\n",
        "# train(train_loader, valid_loader, model, config, device)\n",
        "def train(train_loader, valid_loader, model, config, device):\n",
        "    writer = SummaryWriter() # Writer of tensoboard.\n",
        "    n_epochs, best_loss, step, early_stop_count = config['epochs'], math.inf, 0, 0\n",
        "\n",
        "    \n",
        "    for epoch in range(config['epochs']):\n",
        "    #-----------------------train----------------------#\n",
        "        model.train() # Set your model to train mode.\n",
        "        loss_record = []\n",
        "\n",
        "        # tqdm is a package to visualize your training progress.\n",
        "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
        "\n",
        "        for data, label in train_pbar: ##each batch \n",
        "            optimizer.zero_grad()               # Set gradient to zero.\n",
        "            data, label = data.to(device), label.to(device)   # Move your data to device. \n",
        "            \n",
        "            target = model(data)             \n",
        "            loss = criterion(target, label)\n",
        "            loss.backward()                     # Compute gradient(backpropagation).\n",
        "\n",
        "            optimizer.step()                    # Update parameters.\n",
        "            scheduler.step()\n",
        "\n",
        "            step += 1\n",
        "            loss_record.append(loss.detach().item())\n",
        "            \n",
        "            # Display current epoch number and loss on tqdm progress bar.\n",
        "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
        "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
        "\n",
        "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
        "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
        "\n",
        "    #-----------------------validation----------------------#\n",
        "\n",
        "        model.eval() # Set your model to evaluation mode.\n",
        "        loss_record = []\n",
        "\n",
        "        for data, label in valid_loader:\n",
        "            data, label = data.to(device), label.to(device)   # Move your data to device. \n",
        "            with torch.no_grad():\n",
        "              target = model(data)             \n",
        "              loss = criterion(target, label)\n",
        "            loss_record.append(loss.detach().item())\n",
        "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
        "\n",
        "\n",
        "    #-----------------------print result----------------------#\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
        "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
        "\n",
        "        if mean_valid_loss < best_loss:\n",
        "            best_loss = mean_valid_loss\n",
        "            train_loss_now = mean_train_loss\n",
        "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
        "            print('Saving model with loss {:.3f}...'.format(best_loss))\n",
        "            early_stop_count = 0\n",
        "        else: \n",
        "            early_stop_count += 1\n",
        "\n",
        "        if early_stop_count >= config['early_stop']:\n",
        "            print('\\nModel is not improving, so we halt the training session.')\n",
        "            print('best loss of validation is',best_loss,',at epoch',epoch)\n",
        "            print('loss of training set associated is',train_loss_now)\n",
        "            return\n"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGm1K0OfEiy_"
      },
      "source": [
        "def predict(test_loader, model, device): #final test time: without label\n",
        "    model.eval() # Set your model to evaluation mode.\n",
        "    preds = []\n",
        "    for x in tqdm(test_loader):\n",
        "        x = x.to(device)                        \n",
        "        with torch.no_grad():                   \n",
        "            pred = model(x)                     \n",
        "            preds.append(pred.detach().cpu())   \n",
        "    preds = torch.cat(preds, dim=0).numpy()  \n",
        "    return preds\n"
      ],
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start training"
      ],
      "metadata": {
        "id": "HtEZM15zG6Q8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eX4vxj8EjC1"
      },
      "source": [
        "model = MNISTNet().to(device)\n",
        "\n",
        "# print(model)"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_loader, valid_loader, model, config, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ZuM8cXPbqGaI",
        "outputId": "85a48ce5-d762-4216-87a6-b7e9bfea6b32"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-360-6b882c3c08bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-357-09cb9350f035>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Move your data to device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# Compute gradient(backpropagation).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-352-e89a60636ac6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 1, 28, 28] to have 3 channels, but got 1 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot tensorboard"
      ],
      "metadata": {
        "id": "vUfikoy0Qxfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=./runs/"
      ],
      "metadata": {
        "id": "7WKIXiziQw4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make prediction"
      ],
      "metadata": {
        "id": "F8J6GS3cRP__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    preds = predict(test_loader, model, device)\n",
        "    for i, y in enumerate(preds):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ],
      "metadata": {
        "id": "xlyjBrdpROFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}